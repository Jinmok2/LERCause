{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SoFLIx-rF-N"
   },
   "source": [
    "# LERCause: Causal Sentence Identification with LER (Nuclear Safety Reports)  \n",
    "This code is to use a heurisitc method (keyword matching) on LER data for sentence classification and prediction.   \n",
    "\n",
    "Author:   \n",
    "1. Jinmo Kim: School of Information Sciences, University of Illinois Urbana-Champaign   \n",
    "2. Jenna Kim: School of Information Sciences, Univeristy of Illinois Urbana-Champaign      \n",
    "    \n",
    "Cite this paper:  \n",
    "\n",
    "Kim, J., Kim, J., Lee, A., Kim, J., Diesner, J. (2024). LERCause: Deep learning approaches for causal sentence identification from nuclear safety reports. Plos One. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjDQGl91wA78"
   },
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCQmTfQRrF-S"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install imbalanced-learn library for sampling if not already installed\n",
    " \n",
    "#!pip install imbalanced-learn==0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmfKPvo9wEne"
   },
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiYSV0gaEoYF"
   },
   "outputs": [],
   "source": [
    "def load_data(filename, record):\n",
    "    \n",
    "    \"\"\"\n",
    "       Read in input file and load data\n",
    "    \n",
    "       filename: csv file\n",
    "       colname: column name used for text input data\n",
    "       record: text file to include a processing output\n",
    "    \n",
    "       return two dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' Read in data from input file '''\n",
    "    df = pd.read_csv(filename, encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    ''' Display no of rows and columns '''\n",
    "    print(\"No of Rows: {}\".format(df.shape[0]))\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]))\n",
    "    print(\"No of Rows: {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]), file=record)\n",
    "    \n",
    "    \n",
    "    ''' Select data needed for processing & rename columns '''\n",
    "    df = df[['PMID', 'USENID', 'SENT', 'CLASS']]\n",
    "    df.rename({\"PMID\": \"pmid\", \"USENID\": \"usenid\", \"SENT\": \"sentence\", \"CLASS\": \"label\"}, \n",
    "              axis=1, \n",
    "              inplace=True)\n",
    "    \n",
    "    \n",
    "    ''' Remove null values ''' \n",
    "    df=df.dropna()\n",
    "    \n",
    "    print(\"No of rows (After removing null): {}\".format(df.shape[0]))\n",
    "    print(\"No of columns: {}\".format(df.shape[1]))\n",
    "    print(\"No of rows (After removing null): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of columns: {}\".format(df.shape[1]), file=record)\n",
    "    \n",
    "\n",
    "    ''' Check the first few instances '''  \n",
    "    print(\"\\n<Data View: First Few Instances>\")\n",
    "    print(\"\\n\", df.head()) \n",
    "    print(\"\\n<Data View: First Few Instances>\", file=record)\n",
    "    print(\"\\n\", df.head(), file=record)\n",
    "    \n",
    "    \n",
    "    ''' Display no of lables and rows ''' \n",
    "    print('\\nClass Counts(label, row): Total')\n",
    "    print(df.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Total', file=record)\n",
    "    print(df.label.value_counts(), file=record)\n",
    "    \n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MbxtgNJChay"
   },
   "outputs": [],
   "source": [
    "def sample_data(X_train, \n",
    "                y_train, \n",
    "                record, \n",
    "                sampling=0, \n",
    "                sample_method='over'):  \n",
    "    \"\"\"\n",
    "       Sampling input train data\n",
    "       \n",
    "       X_train: dataframe of X train data\n",
    "       y_train: datafram of y train data\n",
    "       record: text file including a processing output\n",
    "       sampling: indicator of sampling funtion is on or off\n",
    "       sample_method: method of sampling (oversampling or undersampling)\n",
    "       \n",
    "       return two sampled dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    \n",
    "    \n",
    "    ''' Select a sampling method '''\n",
    "    if sampling:\n",
    "        if sample_method == 'over':\n",
    "            oversample = RandomOverSampler(random_state=42)\n",
    "            X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "    \n",
    "            print('\\n************** Data Sampling **************')\n",
    "            print('\\nOversampled Data (class, Rows):\\n{}'.format(y_over.value_counts()))\n",
    "            print('\\n************** Data Sampling **************', file=record)\n",
    "            print('\\nOversampled Data (class, Rows):\\n{}'.format(y_over.value_counts()), file=record)\n",
    "            \n",
    "            X_train_sam, y_train_sam = X_over, y_over\n",
    "            \n",
    "        elif sample_method == 'under':\n",
    "            undersample = RandomUnderSampler(random_state=42)\n",
    "            X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "        \n",
    "            print('\\n************** Data Sampling **************')\n",
    "            print('\\nUndersampled Data (class, Rows):\\n{}'.format(y_under.value_counts()))\n",
    "            print('\\n************** Data Sampling **************', file=record)\n",
    "            print('\\nUndersampled Data (class, Rows):\\n{}'.format(y_under.value_counts()), file=record)\n",
    "            \n",
    "            X_train_sam, y_train_sam = X_under, y_under\n",
    "    else:\n",
    "        X_train_sam, y_train_sam = X_train, y_train \n",
    "        \n",
    "        print('\\n************** Data Sampling **************')\n",
    "        print('\\nNo Sampling Performed\\n')\n",
    "        print('\\n************** Data Sampling **************', file=record)\n",
    "        print('\\nNo Sampling Performed\\n', file=record)\n",
    "    \n",
    "    return X_train_sam, y_train_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0GRsjv3_40h"
   },
   "outputs": [],
   "source": [
    "def find_exact_match(string, keywords):\n",
    "    \"\"\"\n",
    "       Search exact match of terms in a text\n",
    "    \n",
    "       string: text string\n",
    "       keywords: a list of terms used as keyword\n",
    "\n",
    "       return a list of matched terms\n",
    "    \"\"\"\n",
    "  \n",
    "    items = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        term = r'\\b' + keyword + r'\\b'\n",
    "        found = re.findall(term, string, flags=re.IGNORECASE)\n",
    "\n",
    "        if len(found) > 0:\n",
    "            [items.append(word) for word in found]\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jno64EHKulFf"
   },
   "outputs": [],
   "source": [
    "def convert_match_to_label(df_data, keywords):\n",
    "    \"\"\"\n",
    "       Identify strings that match keywords in texts \n",
    "       and convert to label if an instance includes any matched term\n",
    "    \n",
    "       df_data: input dataframe\n",
    "       keywords: a list of terms used as keyword\n",
    "\n",
    "       return: dataframe that includes matched terms and converted labels   \n",
    "    \"\"\"\n",
    "    \n",
    "    import re\n",
    "\n",
    "    ''' Remove punctuation from texts '''\n",
    "    df_data[\"sent_process\"] = df_data[\"sentence\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "    \n",
    "    ''' Remove unnecessary spaces '''\n",
    "    df_data[\"sent_process\"] = df_data[\"sent_process\"].apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "    \n",
    "    ''' Detect keyword terms in each text '''\n",
    "    df_data[\"match\"] = df_data[\"sent_process\"].apply(lambda x: find_exact_match(x, keywords))\n",
    "  \n",
    "\n",
    "    ''' Label each match '''\n",
    "    df_data[\"pred\"] = df_data[\"match\"].apply(lambda x: 1 if len(x)>0 else 0)\n",
    "    \n",
    "    \n",
    "    ''' Select data & rename columns '''\n",
    "    df_data = df_data[[\"pmid\", \"usenid\", \"sentence\", \"match\", \"pred\", \"label\"]]\n",
    "    df_data.rename({\"label\": \"act\"}, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctZ80-2prF-Y"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, \n",
    "                   y_pred, \n",
    "                   record, \n",
    "                   eval_model=0):\n",
    "    \"\"\"\n",
    "      evaluate a model performance\n",
    "      \n",
    "      y_test: original y test data\n",
    "      y_pred: predicted y values\n",
    "      record: text file containing a processing output\n",
    "      eval_model: indicator if this funtion is on or off\n",
    "    \"\"\"\n",
    "    \n",
    "    if eval_model:\n",
    "        \n",
    "        ''' Create a confusion matrix '''\n",
    "        print('\\nConfusion Matrix:\\n')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print('\\nConfusion Matrix:\\n', file=record)\n",
    "        print(confusion_matrix(y_test, y_pred), file=record)\n",
    "        \n",
    "        ''' Display a classification report '''\n",
    "        print('\\nClassification Report:\\n')\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "        print('\\nClassification Report:\\n', file=record)\n",
    "        print(classification_report(y_test, y_pred, digits=4), file=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YROMNEZrF-Z"
   },
   "outputs": [],
   "source": [
    "def main(input_file, \n",
    "         sample_on, \n",
    "         sample_type, \n",
    "         keywords,   \n",
    "         eval_on, \n",
    "         match_file,\n",
    "         result_file):\n",
    "    \n",
    "    \"\"\"\n",
    "       Main function for processing data, model fitting, and prediction\n",
    "       \n",
    "       input_file: input file\n",
    "       sample_on: indicator of sampling on or off\n",
    "       sample_type: type of sampling method\n",
    "       keywords: a list of terms used for keyword matching\n",
    "       eval_on: indicator of model evaluation on or off\n",
    "       match_file: name of csv file to save output\n",
    "       result_file: name of text file to save evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' Open result file for records '''\n",
    "    f=open(result_file, \"a\")\n",
    "    \n",
    "    \n",
    "    ''' Check the processing time '''\n",
    "    proc_start_time = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    ''' Load data '''\n",
    "    print(\"\\n************** Loading Data **************\\n\")\n",
    "    print(\"\\n************** Loading Data **************\\n\", file=f)\n",
    "    \n",
    "    df = load_data(input_file, record=f)       \n",
    "\n",
    "    \n",
    "    ''' Train and test split '''\n",
    "    print(\"\\n************** Spliting Data **************\\n\")\n",
    "    print(\"\\n************** Spliting Data **************\\n\", file=f)\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df.label)\n",
    "    df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42, stratify=df_test.label)\n",
    "    \n",
    "    print(\"Train Data: {}\".format(df_train.shape))\n",
    "    print(\"Val Data: {}\".format(df_val.shape))\n",
    "    print(\"Test Data: {}\".format(df_test.shape))\n",
    "    print(\"Train Data: {}\".format(df_train.shape), file=f)\n",
    "    print(\"Val Data: {}\".format(df_val.shape), file=f)\n",
    "    print(\"Test Data: {}\".format(df_test.shape), file=f)   \n",
    "    \n",
    "    print('\\nClass Counts(label, row): Train')\n",
    "    print(df_train.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Val')\n",
    "    print(df_val.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Test')\n",
    "    print(df_test.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Train', file=f)\n",
    "    print(df_train.label.value_counts(), file=f)\n",
    "    print('\\nClass Counts(label, row): Val', file=f)\n",
    "    print(df_val.label.value_counts(), file=f)\n",
    "    print('\\nClass Counts(label, row): Test', file=f)\n",
    "    print(df_test.label.value_counts(), file=f)\n",
    "    \n",
    "    print(\"\\nTest Data: First Few Instances\")\n",
    "    print(df_test.head())\n",
    "    print(\"\\nTest Data: First Few Instances\", file=f)\n",
    "    print(df_test.head(), file=f)\n",
    "    \n",
    "    \n",
    "    ''' Reset index '''\n",
    "    df_train=df_train.reset_index(drop=True)\n",
    "    df_val=df_val.reset_index(drop=True)\n",
    "    df_test=df_test.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    print(\"\\n************** Processing Data **************\")\n",
    "    print(\"\\n************** Processing Data **************\", file=f)\n",
    "    \n",
    "    print(\"\\nTest Data: {}\".format(df_test.shape))\n",
    "    print(\"\\nTest Data: {}\".format(df_test.shape), file=f)\n",
    "    \n",
    "    print('\\nClass Counts(label, row): Test')\n",
    "    print(df_test.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Test', file=f)\n",
    "    print(df_test.label.value_counts(), file=f)\n",
    "    \n",
    "    print(\"\\nTest Data: First Few Instances\")\n",
    "    print(df_test.head())\n",
    "    print(\"\\nTest Data: First Few Instances\", file=f)\n",
    "    print(df_test.head(), file=f)\n",
    "    \n",
    "    \n",
    "    ''' Sampling '''\n",
    "    if sample_on:\n",
    "        X_train = df_train.iloc[:, :-1]\n",
    "        y_train = df_train.iloc[:, -1]\n",
    "    \n",
    "        X_train_samp, y_train_samp = sample_data(X_train, y_train, sampling=sample_on, sample_method=sample_type)\n",
    "        df_train = pd.concat([X_train_samp, y_train_samp], axis=1)\n",
    "        \n",
    "        print(\"\\nSampled Data: First Few Instances\")\n",
    "        print(df_train.head())\n",
    "        print(\"\\nSampled Data: First Few Instances\", file=f)\n",
    "        print(df_train.head(), file=f)\n",
    "        \n",
    "    \n",
    "    ''' Heuristic Method: keyword matching '''\n",
    "    print(\"\\n************** Heuristic Method: Keyword Match **************\")\n",
    "    print(\"\\n************** Heuristic Method: Keyword Match **************\", file=f)\n",
    "    \n",
    "    df_matched=convert_match_to_label(df_test, keywords)   \n",
    "    \n",
    "    print(\"\\nOutput Data: {}\".format(df_matched.shape))\n",
    "    print(\"\\nOutput Data: {}\".format(df_matched.shape), file=f)\n",
    "    \n",
    "    print(\"\\nOutput Data: First Few Instances\")\n",
    "    print(df_matched.head())\n",
    "    print(\"\\nOutput Data: First Few Instances\", file=f)\n",
    "    print(df_matched.head(), file=f) \n",
    "     \n",
    "\n",
    "    ''' Save output '''\n",
    "    df_matched.to_csv(match_file, \n",
    "                      encoding='utf-8', \n",
    "                      index=False, \n",
    "                      header=True)\n",
    "    \n",
    "    print(\"\\nOutput file:'\" + match_file + \"' Created\")\n",
    "    print(\"\\nOutput file:'\" + match_file + \"' Created\", file=f)\n",
    "    \n",
    "\n",
    "    ''' Evaluate performance '''\n",
    "    print(\"\\n************** Evaluating performance **************\")\n",
    "    print(\"\\n************** Evaluating performance **************\", file=f)\n",
    "\n",
    "    y_test = df_matched[\"act\"]\n",
    "    y_pred = df_matched[\"pred\"]\n",
    "\n",
    "    evaluate_model(y_test, \n",
    "                   y_pred, \n",
    "                   record=f, \n",
    "                   eval_model=eval_on)\n",
    "    \n",
    "    print(\"\\nSummary file:'\" + result_file + \"' Created\")\n",
    "    print(\"\\nSummary file:'\" + result_file + \"' Created\", file=f)\n",
    "    \n",
    "    \n",
    "    ''' Check the processing time '''\n",
    "    proc_elapsed = timeit.default_timer() - proc_start_time\n",
    "    \n",
    "    print(\"\\nTotal Processing Time: {} sec\\n\".format(round(proc_elapsed,2)))\n",
    "    print(\"\\nTotal Processing Time: {} sec\\n\".format(round(proc_elapsed,2)), file=f)\n",
    "    \n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYwmardMwKPF"
   },
   "source": [
    "# 3. Run Code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYt_qbIcrF-a",
    "outputId": "4aa23f86-3670-4af1-f198-35be09ea1c56",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    \n",
    "    ###############################################\n",
    "    ##########  1. Set Parameter Values  ##########\n",
    "    ###############################################\n",
    "    \n",
    "    ########  1-1. Input file name  ########\n",
    "    input_filename=\"LER_rawdata.csv\" \n",
    "  \n",
    "\n",
    "    ########  1-2. Sampling applied?  ########\n",
    "    sampling_on=0                                  # 0 for no sampling; 1 for sampling\n",
    "    sampling_type='under'                          # Use when sampling_on=1;'over'(oversampling)/'under'(undersampling) \n",
    "\n",
    "    \n",
    "    ########  1-3. Evaluation applied?  ######## \n",
    "    eval_on=1                                      # 0 for no; 1 for yes (confusion matrix/classification report)\n",
    "    \n",
    "    \n",
    "    ########  1-4. A list containing terms for keyword matching  ########\n",
    "    keyword_list = ['result in', 'caused', 'due to', 'be caused by', \n",
    "                    'result from', 'as a result of', 'cause of',\n",
    "                    'causes of', 'in response to', 'because', \n",
    "                    'because of', 'attributed to', 'lead to']\n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    ##########   2. Run Main Fuction    ###########\n",
    "    ###############################################\n",
    "    \n",
    "    \n",
    "    output_file = \"result_heuristic.csv\" \n",
    "    eval_file = \"summary_heuristic.txt\" \n",
    "            \n",
    "    main(input_file=input_filename, \n",
    "         sample_on=sampling_on, \n",
    "         sample_type=sampling_type, \n",
    "         keywords=keyword_list,\n",
    "         eval_on=eval_on,\n",
    "         match_file=output_file,\n",
    "         result_file=eval_file)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\\n************** Processing Completed **************\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
