{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5iv-CjeceIf"
   },
   "source": [
    "# LERCause: Causal Sentence Identification with LER (Nuclear Safety Reports)\n",
    "\n",
    "This code is to run pre-trained language models (BERT, BioBERT, SciBERT) on LER data for sentence classification and prediction.  \n",
    "\n",
    "Author:   \n",
    "1. Jinmo Kim: School of Information Sciences, University of Illinois Urbana-Champaign   \n",
    "2. Jenna Kim: School of Information Sciences, Univeristy of Illinois Urbana-Champaign      \n",
    "\n",
    "Cite this paper:   \n",
    "\n",
    "Kim, J., Kim, J., Lee, A., Kim, J., Diesner, J. (2024). LERCause: Deep learning approaches for causal sentence identification from nuclear safety reports. Plos One.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jdls3LTd2EV"
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXZS0zvBe_-e"
   },
   "source": [
    "## 1-1. Install package "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9NHn7cleEe9"
   },
   "source": [
    "Install the transformers package from Hugging Face which is a pytorch interface for working with BERT-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGgZ9871oOL1",
    "outputId": "1067aae9-ef59-4581-c0fd-2f5b00a9d455",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use this command to check if packages are installed\n",
    "\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzsrzXe7c1Oy",
    "outputId": "c505b8d7-5940-4178-f9d9-65e5d00468f5"
   },
   "outputs": [],
   "source": [
    "# Install transformer ver: 4.30.0\n",
    "\n",
    "#!pip install transformers==4.30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bXe5lYvoOL0"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch if this notebook is NOT running on AWS Sagemaker\n",
    "# For AWS Sagemaker, make sure to run this notebook on 'conda_pytorch_p310' kernel. \n",
    "# You can change the kernel type (Go to Kernel menu -> Change kernel)\n",
    "\n",
    "# !pip install torch==1.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvYcGEY5k0sE"
   },
   "source": [
    "## 1-2. Load libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V77AFJ2RjlJ2"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgX3P6tQB8Ao",
    "outputId": "3dc10cec-66f9-4145-a3eb-5f3a1a45000e"
   },
   "outputs": [],
   "source": [
    "# Install imbalanced-learn library for sampling if needed\n",
    "\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMmmPU2Ik3m2",
    "outputId": "8c088e71-d851-4d1b-fc56-60f1daf84798"
   },
   "outputs": [],
   "source": [
    "# Set up for plots and paramters\n",
    "\n",
    "#%matplotlib inline\n",
    "#config InlineBackend.config_format='retina'\n",
    "\n",
    "#sns.set(style='darkgrid', palette='muted', font_scale=1.5)\n",
    "#COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "#sns.set_palette(sns.color_palette(COLORS_PALETTE))\n",
    "\n",
    "#rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "#RANDOM_SEED=42\n",
    "#np.random.seed(RANDOM_SEED)\n",
    "#torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twm3tuiifF2y"
   },
   "source": [
    "## 1-3. Check GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9-5qcHJeaMk",
    "outputId": "97dddad2-da58-4e53-f677-ed0cd1c95f25"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are {:d} GPU(s) available.'.format(torch.cuda.device_count()))\n",
    "    print('We will use the GPU: ', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7tcnC2SoOL3",
    "outputId": "185f8784-8792-4581-8929-237e06a09610"
   },
   "outputs": [],
   "source": [
    "# check GPU memory\n",
    "!nvidia-smi\n",
    "\n",
    "# clear the occupied cuda memory for efficient use\n",
    "\n",
    "# import gc\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "# Kill a process in running if more GPU space is needed\n",
    "# !sudo kill -9 334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5j__pEHeayH"
   },
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OB54atl5oOL7"
   },
   "outputs": [],
   "source": [
    "def load_data(filename, record):\n",
    "    \"\"\"\n",
    "    Read in input file and load data\n",
    "    \n",
    "    filename: csv file   \n",
    "    record: text file to include a processing output\n",
    "    \n",
    "    return two dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' Read in data from input file '''\n",
    "    df = pd.read_csv(filename, encoding='utf-8')\n",
    "    \n",
    "    ''' Display no of rows and columns '''\n",
    "    print(\"No of Rows: {}\".format(df.shape[0]))\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]))\n",
    "    print(\"No of Rows: {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]), file=record)\n",
    "    \n",
    "    \n",
    "    ''' Select data needed for processing & rename columns '''\n",
    "    df = df[['PMID', 'USENID', 'SENT', 'CLASS']]\n",
    "    df.rename({\"PMID\": \"pmid\", \"USENID\": \"usenid\", \"SENT\": \"sentence\", \"CLASS\": \"label\"}, \n",
    "              axis=1, \n",
    "              inplace=True)\n",
    "\n",
    "   \n",
    "    ''' Remove null values '''\n",
    "    df=df.dropna()\n",
    "    \n",
    "    print(\"No of rows (After removing null): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of columns: {}\".format(df.shape[1]), file=record)\n",
    "    print(\"No of rows (After removing null): {}\".format(df.shape[0]))\n",
    "    print(\"No of columns: {}\".format(df.shape[1]))\n",
    "    \n",
    "    \n",
    "    ''' Check the first few instances '''  \n",
    "    print(\"\\n<Data View: First Few Instances>\")\n",
    "    print(\"\\n\", df.head()) \n",
    "    print(\"\\n<Data View: First Few Instances>\", file=record)\n",
    "    print(\"\\n\", df.head(), file=record)\n",
    "    \n",
    "    \n",
    "    ''' Display no of lables and rows ''' \n",
    "    print('\\nClass Counts(label, row): Total')\n",
    "    print(df.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Total', file=record)\n",
    "    print(df.label.value_counts(), file=record)\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8CCdCXooOL8"
   },
   "outputs": [],
   "source": [
    "def token_distribution(df):\n",
    "    \"\"\"\n",
    "       Display a distribution of tokens\n",
    "       \n",
    "       df: a dataframe\n",
    "    \"\"\"\n",
    "        \n",
    "    token_lens = []\n",
    "    long_tokens = []\n",
    "    \n",
    "    \n",
    "    ''' Split text into tokens '''\n",
    "    for pmid, usenid, txt in zip(df.pmid, df.usenid, df.sentence):\n",
    "        tokens = tokenizer.encode(txt, padding=True, truncation=True, max_length=512)\n",
    "        token_lens.append(len(tokens))\n",
    "\n",
    "        ''' Check a sentence with extreme length '''\n",
    "        if len(tokens) > 150:\n",
    "            long_tokens.append((pmid, usenid, len(tokens)))\n",
    "    \n",
    "    print(\"\\n************* Token Distribution: train data *************\")\n",
    "    print(\"long sentences: \")\n",
    "    print(long_tokens)\n",
    "\n",
    "    \n",
    "    ''' Plot the distribution '''\n",
    "    print(\"Min token:\", min(token_lens))\n",
    "    print(\"Max token:\", max(token_lens))\n",
    "\n",
    "    sns.displot(token_lens)\n",
    "    plt.xlim([0,max(token_lens)+10])\n",
    "    plt.xlabel(\"Token Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDmZE8qYoOL8"
   },
   "outputs": [],
   "source": [
    "def sample_data(X_train, \n",
    "                y_train, \n",
    "                record, \n",
    "                sampling=0, \n",
    "                sample_method='over'):  \n",
    "    \"\"\"\n",
    "       Sampling input train data\n",
    "       \n",
    "       X_train: dataframe of X train data\n",
    "       y_train: datafram of y train data\n",
    "       record: text file including a processing output\n",
    "       sampling: indicator of sampling funtion is on or off\n",
    "       sample_method: method of sampling (oversampling or undersampling)\n",
    "       \n",
    "       return two sampled dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    \n",
    "    \n",
    "    ''' Select a sampling method '''\n",
    "    if sampling:\n",
    "        if sample_method == 'over':\n",
    "            oversample = RandomOverSampler(random_state=42)\n",
    "            X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "    \n",
    "            print('\\n************** Data Sampling **************')\n",
    "            print('\\nOversampled Data (class, Rows):\\n{}'.format(y_over.value_counts()))\n",
    "            print('\\n************** Data Sampling **************', file=record)\n",
    "            print('\\nOversampled Data (class, Rows):\\n{}'.format(y_over.value_counts()), file=record)\n",
    "            \n",
    "            X_train_sam, y_train_sam = X_over, y_over\n",
    "            \n",
    "        elif sample_method == 'under':\n",
    "            undersample = RandomUnderSampler(random_state=42)\n",
    "            X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "        \n",
    "            print('\\n************** Data Sampling **************')\n",
    "            print('\\nUndersampled Data (class, Rows):\\n{}'.format(y_under.value_counts()))\n",
    "            print('\\n************** Data Sampling **************', file=record)\n",
    "            print('\\nUndersampled Data (class, Rows):\\n{}'.format(y_under.value_counts()), file=record)\n",
    "            \n",
    "            X_train_sam, y_train_sam = X_under, y_under\n",
    "    else:\n",
    "        X_train_sam, y_train_sam = X_train, y_train \n",
    "        \n",
    "        print('\\n************** Data Sampling **************')\n",
    "        print('\\nNo Sampling Performed\\n')\n",
    "        print('\\n************** Data Sampling **************', file=record)\n",
    "        print('\\nNo Sampling Performed\\n', file=record)\n",
    "    \n",
    "    return X_train_sam, y_train_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5_qP5fQw7p5"
   },
   "outputs": [],
   "source": [
    "class LabelDataset(Dataset):   \n",
    "    \n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        review = \" \".join(review.split())\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            None,                    \n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),            \n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKtOnpVT12oS"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, \n",
    "                       tokenizer, \n",
    "                       max_len, \n",
    "                       batch_size):\n",
    "    \"\"\"\n",
    "       Create a data loader\n",
    "       \n",
    "       df: dataframe \n",
    "       tokenizer: tokenizer\n",
    "       max_len: maximum input length\n",
    "       batch_size: size of batch\n",
    "       \n",
    "       return data loader\n",
    "    \"\"\"\n",
    "    \n",
    "    ds = LabelDataset(\n",
    "        reviews = df.sentence.to_numpy(),\n",
    "        targets = df.label.to_numpy(),\n",
    "        tokenizer = tokenizer,\n",
    "        max_len = max_len)\n",
    "\n",
    "    return DataLoader(ds, batch_size = batch_size, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbwJrTtJSH9m"
   },
   "outputs": [],
   "source": [
    "class LabelClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, pretrained_model):\n",
    "        super(LabelClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        bert_out = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids)\n",
    "        output_dropout = self.dropout(bert_out.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTHCPOsheA30"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples,\n",
    "    outfile):\n",
    "    \"\"\"\n",
    "       Fuction to set up for model training\n",
    "       \n",
    "       model: a model for training\n",
    "       data_loader: data loader\n",
    "       loss_fn: loss function\n",
    "       optimizer: optimizer\n",
    "       device: processing device\n",
    "       scheduler: scheduler\n",
    "       n_examples: number of samples\n",
    "       outfile: file containing a summary of processing output\n",
    "       \n",
    "       return prediction score, mean loss values\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    ''' Load data to a model'''\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        attention_mask = d[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids=token_type_ids)\n",
    "        \n",
    "        ''' Prediction output '''\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"Correct Prediction (Train): {} out of {}\".format(correct_predictions.int(), n_examples), file=outfile)\n",
    "    print(\"Correct Prediction (Train): {} out of {}\".format(correct_predictions.int(), n_examples))\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkBOEEtbhofC"
   },
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    n_examples,\n",
    "    outfile):\n",
    "    \"\"\"\n",
    "      Evaluate a model performance\n",
    "      \n",
    "      model: trained model\n",
    "      data_loader: data loader\n",
    "      loss_fn: loss function\n",
    "      device: processing device\n",
    "      n_examples: number of samples\n",
    "      outfile: file containing a summary of processing output\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            attention_mask = d[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                token_type_ids = token_type_ids\n",
    "                )\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    print(\"Correct Prediction (Eval): {} out of {}\".format(correct_predictions.int(), n_examples), file=outfile)\n",
    "    print(\"Correct Prediction (Eval): {} out of {}\".format(correct_predictions.int(), n_examples))\n",
    "\n",
    "    return correct_predictions.double()/n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHJomabfoOL-"
   },
   "outputs": [],
   "source": [
    "def plot_train_history(history):\n",
    "    \"\"\"\n",
    "       Plot loss and accuracy of training & validation\n",
    "       \n",
    "       history: a dictionary containing a summary of training and valiadation scores\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(history[\"train_acc\"], 'b-o', label=\"train accuracy\")\n",
    "    plt.plot(history[\"val_acc\"], 'r-o', label=\"validation accuracy\")\n",
    "\n",
    "    plt.title(\"Training History\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.xticks(history[\"epoch\"])\n",
    "    plt.yticks(np.arange(0,1.2,step=0.05))\n",
    "    plt.ylim([0,1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvYnWEDsjUKE"
   },
   "outputs": [],
   "source": [
    "def training_loop(epochs,\n",
    "                  modelname,\n",
    "                  model,\n",
    "                  train_data_loader,\n",
    "                  val_data_loader,\n",
    "                  loss_fn,\n",
    "                  optimizer,\n",
    "                  device,\n",
    "                  scheduler,\n",
    "                  n_train,\n",
    "                  n_val,\n",
    "                  model_file,\n",
    "                  record):\n",
    "    \"\"\"\n",
    "      Controller for a training process\n",
    "      \n",
    "      epochs: number of epoch\n",
    "      modelname: name of selected model\n",
    "      model: model for training\n",
    "      train_data_loader: data loader for training\n",
    "      val_data_loader: data loader for validation\n",
    "      loss_fn: loss function\n",
    "      optimizer: optimizer\n",
    "      device: processing device\n",
    "      scheduler: scheduler\n",
    "      n_train: number of train samples\n",
    "      n_val: number of validation samples\n",
    "      model_file: file to save trained model\n",
    "      record: file containing a summary of processing output\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n********** \" + modelname + \" **********\")\n",
    "    print(\"\\n********** \" + modelname + \" **********\", file=record) \n",
    "\n",
    "    history = defaultdict(list)\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    ''' Train and evaluation'''\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nEpoch {} / {}\".format(str(epoch + 1), str(epochs)))\n",
    "        print(\"-\" * 60)\n",
    "        print(\"\\nEpoch {} / {}\".format(str(epoch + 1), str(epochs)), file=record)\n",
    "        print(\"-\" * 60, file=record)\n",
    "\n",
    "        train_acc, train_loss = train_model(model,\n",
    "                                            train_data_loader,\n",
    "                                            loss_fn,\n",
    "                                            optimizer,\n",
    "                                            device,\n",
    "                                            scheduler,\n",
    "                                            n_train,\n",
    "                                            outfile=record)\n",
    "        \n",
    "        print(\"Train Loss: {}, Accuracy: {}\\n\".format(train_loss, train_acc))\n",
    "        print(\"Train Loss: {}, Accuracy: {}\\n\".format(train_loss, train_acc), file=record)\n",
    "        \n",
    "\n",
    "        val_acc, val_loss = eval_model(model,\n",
    "                                       val_data_loader,\n",
    "                                       loss_fn,\n",
    "                                       device,\n",
    "                                       n_val,\n",
    "                                       outfile=record)\n",
    "        \n",
    "        print(\"Validation Loss: {}, Accuracy: {}\".format(val_loss, val_acc))\n",
    "        print(\"Validation Loss: {}, Accuracy: {}\".format(val_loss, val_acc), file=record)\n",
    "        \n",
    "\n",
    "        ''' Save the state of the best model '''\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "            if model_file:\n",
    "                torch.save(model.state_dict(), model_file)\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "    \n",
    "    ''' Plot training & validation accuracy '''\n",
    "    #plot_train_history(history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iJYc8yzn02l"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, \n",
    "                    data_loader, \n",
    "                    device):\n",
    "    \"\"\"\n",
    "      Predict label class\n",
    "      \n",
    "      model: trained model\n",
    "      data_loader: data loader\n",
    "      device: processing device\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    review_texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        ''' Get output from the model with test data'''\n",
    "        for d in data_loader:\n",
    "            texts = d[\"text\"]\n",
    "            input_ids = d[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            attention_mask = d[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                token_type_ids = token_type_ids\n",
    "            )\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            ''' Normalize the raw output to get probability for each clas '''\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            #probs = torch.sigmoid(outputs)\n",
    "\n",
    "            review_texts.extend(texts)\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(probs)\n",
    "            real_values.extend(targets)\n",
    "\n",
    "    ''' Move output to cpu for calculation '''\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "\n",
    "    return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAxJl4eFoOL_"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, \n",
    "                   y_pred, \n",
    "                   record, \n",
    "                   eval_model=0):\n",
    "    \"\"\"\n",
    "      evaluate a model performance\n",
    "      \n",
    "      y_test: original y test data\n",
    "      y_pred: predicted y values\n",
    "      record: text file containing a processing output\n",
    "      eval_model: indicator if this funtion is on or off\n",
    "    \"\"\"\n",
    "    \n",
    "    if eval_model:\n",
    "        \n",
    "        ''' Create a confusion matrix '''\n",
    "        print('\\nConfusion Matrix:\\n')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print('\\nConfusion Matrix:\\n', file=record)\n",
    "        print(confusion_matrix(y_test, y_pred), file=record)\n",
    "        \n",
    "        ''' Display a classification report '''\n",
    "        print('\\nClassification Report:\\n')\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "        print('\\nClassification Report:\\n', file=record)\n",
    "        print(classification_report(y_test, y_pred, digits=4), file=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQD2oIhdoOL_"
   },
   "outputs": [],
   "source": [
    "def predict_proba(df_test, y_text, y_test, y_pred, y_pred_probs, proba_file, proba_on=0):\n",
    "\n",
    "    \"\"\"\n",
    "       Predict probability of each class\n",
    "\n",
    "       df_test: original X test data\n",
    "       y_text: text data sentence\n",
    "       y_test: original y test data\n",
    "       y_pred: predicted y values\n",
    "       y_pred_probs: probability scores of prediction\n",
    "       proba_file: output file of probability scores\n",
    "       proba_on: decide if the probability output is expected\n",
    "\n",
    "    \"\"\"\n",
    "    if proba_on:\n",
    "        \n",
    "        df_result = pd.DataFrame({\n",
    "            'pmid': df_test[\"pmid\"],\n",
    "            'usenid': df_test[\"usenid\"],\n",
    "            'sentence': y_text,\n",
    "            'prob_0': y_pred_probs[:, 0],\n",
    "            'prob_1': y_pred_probs[:, 1],\n",
    "            'pred': y_pred,\n",
    "            'act': y_test})\n",
    "\n",
    "        df_result.to_csv(proba_file, encoding='utf-8', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(input_file, \n",
    "               result_file):\n",
    "    \"\"\"\n",
    "       Split data from input file\n",
    "       \n",
    "       input_file: file containing input data \n",
    "       result_file: name of output file of evaluation\n",
    "       \n",
    "       return X and y dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' Open result file for records '''\n",
    "    f=open(result_file, \"a\")\n",
    "    \n",
    "    \n",
    "    ''' Load data '''\n",
    "    print(\"\\n************** Loading Data ************\\n\")\n",
    "    print(\"\\n************** Loading Data ************\\n\", file=f)\n",
    "    \n",
    "    df = load_data(input_file, record=f)\n",
    "    \n",
    "    \n",
    "    ''' Train and test split '''\n",
    "    print(\"\\n************** Spliting Data **************\\n\")\n",
    "    print(\"\\n************** Spliting Data **************\\n\", file=f)\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df.label)\n",
    "    df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42, stratify=df_test.label)\n",
    "    \n",
    "    print(\"Train Data: {}\".format(df_train.shape))\n",
    "    print(\"Val Data: {}\".format(df_val.shape))\n",
    "    print(\"Test Data: {}\".format(df_test.shape))\n",
    "    print(\"Train Data: {}\".format(df_train.shape), file=f)\n",
    "    print(\"Val Data: {}\".format(df_val.shape), file=f)\n",
    "    print(\"Test Data: {}\".format(df_test.shape), file=f)\n",
    "    \n",
    "    print('\\nClass Counts(label, row): Train')\n",
    "    print(df_train.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Val')\n",
    "    print(df_val.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Test')\n",
    "    print(df_test.label.value_counts())\n",
    "    print('\\nClass Counts(label, row): Train', file=f)\n",
    "    print(df_train.label.value_counts(), file=f)\n",
    "    print('\\nClass Counts(label, row): Val', file=f)\n",
    "    print(df_val.label.value_counts(), file=f)\n",
    "    print('\\nClass Counts(label, row): Test', file=f)\n",
    "    print(df_test.label.value_counts(), file=f)\n",
    "    \n",
    "    print(\"\\nTest Data\")\n",
    "    print(df_test.head())\n",
    "    print(\"\\nTest Data\", file=f)\n",
    "    print(df_test.head(), file=f)\n",
    "    \n",
    "        \n",
    "    return (df_train, df_val, df_test)\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(df_train, \n",
    "                df_val,\n",
    "                datasize_change,\n",
    "                sample_balance,\n",
    "                balance_sampling_on,                                   \n",
    "                balance_sampling_type,\n",
    "                sample_ratio,\n",
    "                ratio,\n",
    "                sample_on, \n",
    "                sample_type, \n",
    "                tokenizer,\n",
    "                max_len,\n",
    "                batch_size,\n",
    "                modelname,\n",
    "                n_class,\n",
    "                device,\n",
    "                pretrained_model,\n",
    "                learning_rate,\n",
    "                epochs,\n",
    "                model_file,\n",
    "                result_file):  \n",
    "    \"\"\"\n",
    "       Function for data processing and model fitting\n",
    "       \n",
    "       df_train: dataframe containing train data \n",
    "       df_val: dataframe containing validation data\n",
    "       datasize_change: data size change on or off\n",
    "       sample_balance: balance of sample on or off\n",
    "       balance_sampling_on: sampling on or off when balance is 1\n",
    "       balance_samplling_type: sample type to choose if balance_sampling_on is 1\n",
    "       sample_ratio: proportion of data size for balance sampling\n",
    "       ratio: proportion of data size\n",
    "       sample_on: sampling on or off\n",
    "       sample_type: sample type to choose if sample_on is 1\n",
    "       tokenizer: file containing tokenizer\n",
    "       max_len: maximun length of tokens\n",
    "       eval_on: model evaluation on or off\n",
    "       tokenizer_file: file to save tokenizer\n",
    "       max_len: maximun length of tokens\n",
    "       batch_size: size of batch \n",
    "       modelname: name of selected model\n",
    "       n_class: number of label class\n",
    "       device: processing device\n",
    "       pretrained_model: path to model for training\n",
    "       learning_rate: learning rate\n",
    "       epochs: number of epoch\n",
    "       model_file: file to save model\n",
    "       result_file: output file for records\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' Open result file for records '''\n",
    "    f = result_file\n",
    "    \n",
    "    ''' Data size change '''    \n",
    "    if datasize_change:\n",
    "        \n",
    "        ''' Sample data with balance (1:1) '''\n",
    "        if sample_balance:\n",
    "            \n",
    "            print(\"\\n************** Data Balancing: Label Class (1:1) *************\\n\")\n",
    "            print(\"\\n************** Data Balancing: Label Class (1:1) *************\\n\", file=f)\n",
    "            \n",
    "            X_train = df_train.iloc[:, :-1]\n",
    "            y_train = df_train.iloc[:, -1]\n",
    "\n",
    "            X_train_samp, y_train_samp = sample_data(X_train, \n",
    "                                                     y_train, \n",
    "                                                     record=f, \n",
    "                                                     sampling=balance_sampling_on,\n",
    "                                                     sample_method=balance_sampling_type)\n",
    "\n",
    "            df_train_concat = pd.concat([X_train_samp, y_train_samp], axis=1)\n",
    "            df_train = df_train_concat\n",
    "            \n",
    "            print('\\nClass Counts(label, row): After balancing')\n",
    "            print(df_train.label.value_counts())\n",
    "            print('\\nClass Counts(label, row): After balancing', file=f)\n",
    "            print(df_train.label.value_counts(), file=f)\n",
    "            \n",
    "            print(\"\\n<Balanced Train Data>\")\n",
    "            print(df_train.head())\n",
    "            print(\"\\n<Balanced Train Data>\", file=f)\n",
    "            print(df_train.head(), file=f)\n",
    "           \n",
    "        \n",
    "        ''' Sample data based on size ratio '''     \n",
    "        if sample_ratio:\n",
    "            \n",
    "            X_train = df_train.iloc[:, :-1]\n",
    "            y_train = df_train.iloc[:, -1]\n",
    "            \n",
    "            if ratio == 1:\n",
    "                X_train = X_train\n",
    "                y_train = y_train       \n",
    "            else:\n",
    "                X_train, _, y_train, _ = train_test_split(X_train, \n",
    "                                                          y_train, \n",
    "                                                          train_size=ratio, \n",
    "                                                          random_state=42, \n",
    "                                                          stratify=y_train)\n",
    "            \n",
    "            ''' Combine x_train and y_train data '''\n",
    "            df_train = pd.concat([X_train, y_train], axis=1)\n",
    "            \n",
    "            print(\"\\n************** Data Size Change: Ratio *************\\n\")\n",
    "            print(\"Data Ratio: {}\".format(ratio))\n",
    "            print(\"\\n************** Data Size Change: Ratio *************\\n\", file=f)\n",
    "            print(\"Data Ratio: {}\".format(ratio), file=f)\n",
    "            \n",
    "            print('\\nClass Counts(label, row): After sampling')\n",
    "            print(df_train.label.value_counts())\n",
    "            print('\\nClass Counts(label, row): After sampling', file=f)\n",
    "            print(df_train.label.value_counts(), file=f)\n",
    "            \n",
    "            print(\"\\n<Train Data Based on Ratio>\")\n",
    "            print(df_train.head())\n",
    "            print(\"\\n<Train Data Based on Ratio>\", file=f)\n",
    "            print(df_train.head(), file=f)\n",
    "            \n",
    "    \n",
    "        ''' Reset index '''\n",
    "        df_train=df_train.reset_index(drop=True)\n",
    "        \n",
    "        print(\"\\n************** Processing Data **************\")\n",
    "        print(\"\\nTrain Data: {}\".format(df_train.shape))\n",
    "        print(\"\\n************** Processing Data **************\", file=f)\n",
    "        print(\"\\nTrain Data: {}\".format(df_train.shape), file=f)\n",
    "        \n",
    "        print('\\nClass Counts(label, row): Train')\n",
    "        print(df_train.label.value_counts())\n",
    "        print('\\nClass Counts(label, row): Train', file=f)\n",
    "        print(df_train.label.value_counts(), file=f)\n",
    "        \n",
    "        print(\"\\n<Train Data>\")\n",
    "        print(df_train.head())\n",
    "        print(\"\\n<Train Data>\", file=f)\n",
    "        print(df_train.head(), file=f)\n",
    "        \n",
    "    \n",
    "    ''' Sampling '''\n",
    "    if sample_on:\n",
    "        X_train = df_train.iloc[:, :-1]\n",
    "        y_train = df_train.iloc[:, -1]\n",
    "\n",
    "        X_train_samp, y_train_samp = sample_data(X_train, \n",
    "                                                 y_train, \n",
    "                                                 record=f, \n",
    "                                                 sampling=balance_sampling_on,\n",
    "                                                 sample_method=balance_sampling_type)\n",
    "\n",
    "        df_train = pd.concat([X_train_samp, y_train_samp], axis=1)\n",
    "        \n",
    "        print(\"\\nSampled Data: First Few Instances\")\n",
    "        print(df_train.head())\n",
    "        print(\"\\nSampled Data: First Few Instances\", file=f)\n",
    "        print(df_train.head(), file=f)\n",
    "        \n",
    "        \n",
    "    ''' Transform data '''\n",
    "    train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
    "    val_data_loader = create_data_loader(df_val, tokenizer, max_len, batch_size)\n",
    "    \n",
    "    \n",
    "    ''' Fitting a model '''\n",
    "    print(\"\\n************** Training Model: '\" + modelname + \"' **************\")\n",
    "    print(\"\\n************** Training Model: '\" + modelname + \"' **************\", file=f)\n",
    "\n",
    "    n_train = len(df_train)\n",
    "    n_val = len(df_val)\n",
    "\n",
    "    \n",
    "    ''' Create a classifier instance and move it to GPU '''\n",
    "    model = LabelClassifier(n_class, pretrained_model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    \n",
    "    ''' Optimizer, scheduler, loss function '''\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, correct_bias=False)\n",
    "    total_steps = len(train_data_loader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, \n",
    "                                                num_training_steps = total_steps)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    ''' Loop training with epochs '''\n",
    "    training_loop(epochs, modelname, model, train_data_loader, val_data_loader,\n",
    "                loss_fn, optimizer, device, scheduler, n_train, n_val, model_file, record=f)\n",
    "    \n",
    "    print(\"\\n\\nTrained model: '\" + model_file + \"' saved in the local directory\")   \n",
    "    print(\"\\n\\nTrained model: '\" + model_file + \"' saved in the local directory\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(df_test,\n",
    "                    pretrained_model,\n",
    "                    model_file,\n",
    "                    n_class,\n",
    "                    device,\n",
    "                    tokenizer,\n",
    "                    max_len,\n",
    "                    batch_size,\n",
    "                    eval_on,\n",
    "                    proba_on,\n",
    "                    proba_file,\n",
    "                    result_file):\n",
    "    \"\"\"\n",
    "       Function for prediction and evaluation\n",
    "       \n",
    "       df_test: dataframe containing test data \n",
    "       pretrained_model: path to model for training\n",
    "       model_file: file containing trained model\n",
    "       n_class: number of label class\n",
    "       device: processing device\n",
    "       tokenizer: tokenizer\n",
    "       max_len: maximun length of tokens\n",
    "       batch_size: size of batch\n",
    "       eval_on: model evaluation on or off\n",
    "       proba_on: probability on or off\n",
    "       proba_file: output file to save probability\n",
    "       result_file: name of output file of evaluation\n",
    "    \"\"\"\n",
    "      \n",
    "    ''' Open result file for records '''\n",
    "    f = result_file\n",
    "    \n",
    "    \n",
    "    ''' Load trained model '''    \n",
    "    model = LabelClassifier(n_class, pretrained_model)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(\"\\nA trained model from '\" + model_file + \"' loaded\")\n",
    "    print(\"\\nA trained model from '\" + model_file + \"' loaded\", file=f)\n",
    "    \n",
    "    \n",
    "    ''' Get Predictions '''\n",
    "    print(\"\\n************** Getting Predictions **************\", file=f)\n",
    "    print(\"\\n************** Getting Predictions **************\")\n",
    "    \n",
    "    \n",
    "    ''' Load tokenizer and transform test data '''\n",
    "    print(\"\\nTest Data: First Few Instances\")\n",
    "    print(df_test.head())\n",
    "    print(\"\\nTest Data: First Few Instances\", file=f)\n",
    "    print(df_test.head(), file=f)\n",
    "    \n",
    "    test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)\n",
    "    \n",
    "    \n",
    "    ''' Predict class '''\n",
    "    y_text, y_pred, y_pred_probs, y_test = get_predictions(model, \n",
    "                                                           test_data_loader, \n",
    "                                                           device)\n",
    "    \n",
    "\n",
    "    ''' Evaluate model performance '''\n",
    "    print(\"\\n************** Evaluating Performance **************\", file=f)\n",
    "    print(\"\\n************** Evaluating Performance **************\")\n",
    "    evaluate_model(y_test, y_pred, record=f, eval_model=eval_on)\n",
    "    \n",
    "\n",
    "    ''' Generate output with probability scores '''   \n",
    "    predict_proba(df_test, \n",
    "                  y_text, \n",
    "                  y_test, \n",
    "                  y_pred, \n",
    "                  y_pred_probs, \n",
    "                  proba_file=proba_file, \n",
    "                  proba_on=proba_on)\n",
    "    \n",
    "    if proba_on:\n",
    "        print(\"\\nOutput file:'\" + proba_file + \"' Created\", file=f)\n",
    "        print(\"\\nOutput file:'\" + proba_file + \"' Created\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df_train, \n",
    "         df_val, \n",
    "         df_test, \n",
    "         mode,\n",
    "         datasize_change,\n",
    "         sample_balance,\n",
    "         balance_sampling_on,                                   \n",
    "         balance_sampling_type,\n",
    "         sample_ratio,\n",
    "         ratio,\n",
    "         sample_on, \n",
    "         sample_type, \n",
    "         tokenizer,\n",
    "         max_len,\n",
    "         batch_size,\n",
    "         modelname,\n",
    "         n_class,\n",
    "         device,\n",
    "         pretrained_model,\n",
    "         learning_rate,\n",
    "         epochs,\n",
    "         model_file,\n",
    "         eval_on,\n",
    "         proba_on,\n",
    "         proba_file,\n",
    "         result_file):\n",
    "    \n",
    "    ''' Open result file for records '''\n",
    "    record = open(result_file, \"a\")\n",
    "    \n",
    "    ''' Check the processing time '''\n",
    "    proc_start_time = timeit.default_timer()\n",
    "    \n",
    "    ''' Select a mode for training or testing'''\n",
    "    if mode == \"train\":\n",
    "        \n",
    "        model_train(df_train, \n",
    "                    df_val, \n",
    "                    datasize_change, \n",
    "                    sample_balance, \n",
    "                    balance_sampling_on,                                   \n",
    "                    balance_sampling_type, \n",
    "                    sample_ratio, \n",
    "                    ratio, \n",
    "                    sample_on, \n",
    "                    sample_type, \n",
    "                    tokenizer, \n",
    "                    max_len, \n",
    "                    batch_size, \n",
    "                    modelname, \n",
    "                    n_class, \n",
    "                    device, \n",
    "                    pretrained_model,\n",
    "                    learning_rate, \n",
    "                    epochs, \n",
    "                    model_file, \n",
    "                    result_file=record) \n",
    "    \n",
    "    elif mode == \"test\":\n",
    "        \n",
    "        model_inference(df_test, \n",
    "                        pretrained_model, \n",
    "                        model_file, \n",
    "                        n_class, \n",
    "                        device, \n",
    "                        tokenizer, \n",
    "                        max_len,\n",
    "                        batch_size, \n",
    "                        eval_on, \n",
    "                        proba_on, \n",
    "                        proba_file, \n",
    "                        result_file=record)\n",
    "    \n",
    "    \n",
    "    ''' Check the processing time '''\n",
    "    proc_elapsed = timeit.default_timer() - proc_start_time\n",
    "    \n",
    "    print(\"\\n************** Processing Time **************\")\n",
    "    print(\"\\n{}: {} sec\\n\".format(mode, round(proc_elapsed,2)))\n",
    "    print(\"\\n************** Processing Time **************\", file=record)\n",
    "    print(\"\\n{}: {} sec\\n\".format(mode, round(proc_elapsed,2)), file=record)\n",
    "    \n",
    "    print(\"\\nSummary file:'\" + result_file + \"' Created\\n\")\n",
    "    print(\"\\nSummary file:'\" + result_file + \"' Created\\n\", file=record)\n",
    "    \n",
    "    record.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbPpOVyVoOMA"
   },
   "source": [
    "# 3. Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RxI-Z6FoOMA",
    "outputId": "f2383ce9-4460-4d8b-ef5a-ae2a26d46015",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__== \"__main__\":\n",
    "\n",
    "    ###############################################\n",
    "    ##########  1. Set Parameter Values  ##########\n",
    "    ###############################################\n",
    "\n",
    "    ########  1-1. Input file name  ########\n",
    "    input_filename=\"LER_rawdata.csv\"\n",
    "    \n",
    "        \n",
    "    ########  1-2. Which mode to run?  ########   \n",
    "    mode_name = \"data-split\"                                    # 3 options: \"data-split\", \"train\", \"test\"\n",
    "                                                                # Use \"data-split\" before \"train\" or/and \"test\"\n",
    "    \n",
    "    ########  1-3. Data size change?  ########\n",
    "    ## 1-3-1. Change on/off?\n",
    "    datachange_on = 0                                           # 0 for no change; 1 for change of data size\n",
    "    \n",
    "    ## 1-3-2. class balance (1:1)?\n",
    "    balance_on = 0                                              # 0 for no balance; 1 for class balance (1:1)\n",
    "    balance_sample_on = 0                                       # 0 for no sampling; 1 for sampling\n",
    "    balance_sample_type = 'under'                               # 'over'(oversampling); 'under'(undersampling)\n",
    "    balance_str = 'balance' + str(balance_on) + '_'\n",
    "    \n",
    "    ## 1-3-3. data increase?\n",
    "    ratio_on = 0                                                # 0 for no ratio; 1 for ratio for data size\n",
    "    ratio_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  # a list containing ratio numbers\n",
    "\n",
    "    \n",
    "    ########  1-4. Sampling applied?  ########\n",
    "    sampling_on = 0                                             # 0 for no sampling; 1 for sampling\n",
    "    sampling_type = 'over'                                      # 'over'(oversampling)/'under'(undersampling)\n",
    "    \n",
    "    \n",
    "    ########  1-5. Which BERT-based model to use?  ########\n",
    "    pretrained_modelname = 'bert-base-cased'\n",
    "    #pretrained_modelname = 'dmis-lab/biobert-base-cased-v1.1'\n",
    "    #pretrained_modelname = 'allenai/scibert_scivocab_cased'\n",
    "\n",
    "    if mode_name == \"train\" or mode_name == \"test\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(pretrained_modelname)\n",
    "    \n",
    "    modelname = pretrained_modelname.split(\"/\")[-1]\n",
    "    \n",
    "    \n",
    "    ########  1-6. Binary or multi classification?  ########\n",
    "    num_class = 2                                              # number of label class\n",
    "    \n",
    "\n",
    "    ########  1-7. Check token distribution for MAX_LEN value: uncommentize if needed  ########\n",
    "    #print(\"\\n************** Token Distribution **************\")\n",
    "    #df_token = load_data(input_filename, record=None)\n",
    "    #token_distribution(df_token)\n",
    "\n",
    "    \n",
    "    ########  1-8. Hyperparameters for BERT?  ########        \n",
    "    MAX_LEN = 150                                             \n",
    "    BATCH_SIZE = 16                                          \n",
    "    EPOCHS = 4                                                \n",
    "    LEARNING_RATE = 2e-5                                     \n",
    "\n",
    "    \n",
    "    ########  1-9. Evaluation & probability file  ########\n",
    "    eval_on = 1                                               # 0 for no; 1 for yes (evaluation scores)\n",
    "    proba_on = 1                                              # 0 for no; 1 for yes (probability & prediction output)\n",
    "\n",
    " \n",
    "    ###############################################\n",
    "    ##########   2. Run Main Fuction    ###########\n",
    "    ###############################################\n",
    "\n",
    "    if mode_name == \"data-split\": \n",
    "        eval_file = \"summary_bert_\" + mode_name + \".txt\" \n",
    "        df_train, df_val, df_test = split_data(input_filename, eval_file)\n",
    "        \n",
    "    else:\n",
    "        if datachange_on:\n",
    "            for ratio in ratio_list:\n",
    "                if sampling_on:\n",
    "                    model_file=\"model_bert_\"+balance_str+str(ratio)+\"_\"+sampling_type+\"_\"+modelname+\".bin\"\n",
    "                    proba_file=\"result_bert_\"+balance_str+str(ratio)+\"_\"+sampling_type+\"_\"+modelname+\".csv\"\n",
    "                    eval_file=\"summary_bert_\"+mode_name+\"_\"+balance_str+str(ratio)+\"_\"+sampling_type+\"_\"+modelname+\".txt\"\n",
    "                \n",
    "                else:\n",
    "                    model_file=\"model_bert_\"+balance_str+\"_\"+str(ratio)+\"_\"+modelname+\".bin\"\n",
    "                    proba_file=\"result_bert_\"+balance_str+\"_\"+str(ratio)+\"_\"+modelname+\".csv\"\n",
    "                    eval_file=\"summary_bert_\"+mode_name+\"_\"+balance_str+\"_\"+str(ratio)+\"_\"+modelname+\".txt\"  \n",
    "\n",
    "                main(df_train, \n",
    "                     df_val, \n",
    "                     df_test, \n",
    "                     mode=mode_name, \n",
    "                     datasize_change=datachange_on,\n",
    "                     sample_balance=balance_on, \n",
    "                     balance_sampling_on=balance_sample_on,                                      \n",
    "                     balance_sampling_type=balance_sample_type, \n",
    "                     sample_ratio=ratio_on,\n",
    "                     ratio=ratio, \n",
    "                     sample_on=sampling_on, \n",
    "                     sample_type=sampling_type,\n",
    "                     tokenizer=tokenizer, \n",
    "                     max_len=MAX_LEN, \n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     modelname=modelname, \n",
    "                     n_class=num_class, \n",
    "                     device=device,\n",
    "                     pretrained_model=pretrained_modelname, \n",
    "                     learning_rate=LEARNING_RATE,\n",
    "                     epochs=EPOCHS, \n",
    "                     model_file=model_file, \n",
    "                     eval_on=eval_on,\n",
    "                     proba_on=proba_on, \n",
    "                     proba_file=proba_file, \n",
    "                     result_file=eval_file)\n",
    "                        \n",
    "        else:\n",
    "            if sampling_on:\n",
    "                model_file=\"model_bert_\"+sampling_type+\"_\"+modelname+\".bin\"\n",
    "                proba_file=\"result_bert_\"+sampling_type+\"_\"+modelname+\".csv\"\n",
    "                eval_file=\"summary_bert_\"+mode_name+\"_\"+sampling_type+\"_\"+modelname+\".txt\"\n",
    "            else:\n",
    "                model_file=\"model_bert_\"+modelname+\".bin\"\n",
    "                proba_file=\"result_bert_\"+modelname+\".csv\"\n",
    "                eval_file=\"summary_bert_\"+mode_name+\"_\"+modelname+\".txt\"\n",
    "                \n",
    "            main(df_train, \n",
    "                 df_val, \n",
    "                 df_test, \n",
    "                 mode=mode_name, \n",
    "                 datasize_change=datachange_on,\n",
    "                 sample_balance=balance_on, \n",
    "                 balance_sampling_on=balance_sample_on,                                      \n",
    "                 balance_sampling_type=balance_sample_type, \n",
    "                 sample_ratio=ratio_on,\n",
    "                 ratio=1, \n",
    "                 sample_on=sampling_on, \n",
    "                 sample_type=sampling_type,\n",
    "                 tokenizer=tokenizer, \n",
    "                 max_len=MAX_LEN, \n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 modelname=modelname, \n",
    "                 n_class=num_class, \n",
    "                 device=device,\n",
    "                 pretrained_model=pretrained_modelname, \n",
    "                 learning_rate=LEARNING_RATE,\n",
    "                 epochs=EPOCHS, \n",
    "                 model_file=model_file, \n",
    "                 eval_on=eval_on,\n",
    "                 proba_on=proba_on, \n",
    "                 proba_file=proba_file, \n",
    "                 result_file=eval_file)\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n************** Processing Complete **************\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
